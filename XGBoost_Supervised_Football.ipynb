{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hyperopt\n",
    "#https://hyperopt.github.io/hyperopt/?source=post_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset (football_cleaned_supervised.csv)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data):\n",
    "    df = pd.read_csv(data)\n",
    "   \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football= load_dataset('cleaned_files/football_clean_supervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SKILL</th>\n",
       "      <th>STARCOLL</th>\n",
       "      <th>NUMOFF</th>\n",
       "      <th>POS</th>\n",
       "      <th>HEIGHT_IN</th>\n",
       "      <th>WEIGHT_LBS</th>\n",
       "      <th>...</th>\n",
       "      <th>TIK_LONG</th>\n",
       "      <th>TOT_FOL</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>RECRUIT_YEAR</th>\n",
       "      <th>EXP_MONTHS</th>\n",
       "      <th>EXP_YEARS</th>\n",
       "      <th>institution_name_short</th>\n",
       "      <th>ClassificationCode</th>\n",
       "      <th>REV_MEN</th>\n",
       "      <th>EXP_MEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arch Manning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.28281</td>\n",
       "      <td>99.53</td>\n",
       "      <td>Texas</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>73900.0</td>\n",
       "      <td>football</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.172603</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161532860.0</td>\n",
       "      <td>50633156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Anthony Hill</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>97.87</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>football</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.172603</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161532860.0</td>\n",
       "      <td>50633156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CJ Baxter Jr.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>97.26</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10900.0</td>\n",
       "      <td>football</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.172603</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161532860.0</td>\n",
       "      <td>50633156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Johntay Cook II</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>97.23</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>153800.0</td>\n",
       "      <td>football</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.172603</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161532860.0</td>\n",
       "      <td>50633156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Malik Muhammad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>96.22</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>football</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.172603</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161532860.0</td>\n",
       "      <td>50633156.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             NAME  GRADE       AGE  SKILL STARCOLL  NUMOFF  POS  \\\n",
       "0           0     Arch Manning    2.0  18.28281  99.53    Texas    18.0  1.0   \n",
       "1           1     Anthony Hill    2.0  18.00000  97.87    Texas    25.0  8.0   \n",
       "2           2    CJ Baxter Jr.    2.0  18.00000  97.26    Texas    25.0  9.0   \n",
       "3           3  Johntay Cook II    2.0  18.00000  97.23    Texas    25.0  3.0   \n",
       "4           4   Malik Muhammad    2.0  19.00000  96.22    Texas    25.0  7.0   \n",
       "\n",
       "   HEIGHT_IN  WEIGHT_LBS  ...  TIK_LONG   TOT_FOL     SPORT  RECRUIT_YEAR  \\\n",
       "0       75.5       220.0  ...    8900.0   73900.0  football        2023.0   \n",
       "1       73.5       225.0  ...       0.0   13100.0  football        2023.0   \n",
       "2       73.0       216.0  ...    1700.0   10900.0  football        2023.0   \n",
       "3       71.0       175.0  ...  136000.0  153800.0  football        2023.0   \n",
       "4       72.0       180.0  ...    8100.0   16200.0  football        2023.0   \n",
       "\n",
       "   EXP_MONTHS  EXP_YEARS institution_name_short  ClassificationCode  \\\n",
       "0         2.0   0.172603                  Texas                 1.0   \n",
       "1         2.0   0.172603                  Texas                 1.0   \n",
       "2         2.0   0.172603                  Texas                 1.0   \n",
       "3         2.0   0.172603                  Texas                 1.0   \n",
       "4         2.0   0.172603                  Texas                 1.0   \n",
       "\n",
       "       REV_MEN     EXP_MEN  \n",
       "0  161532860.0  50633156.0  \n",
       "1  161532860.0  50633156.0  \n",
       "2  161532860.0  50633156.0  \n",
       "3  161532860.0  50633156.0  \n",
       "4  161532860.0  50633156.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_football.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Unnamed:0 and Sport column- not necessary \n",
    "def drop_col(df):\n",
    "    df=df.drop(columns=['Unnamed: 0', 'SPORT'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football = drop_col(df_football)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      0\n",
       "GRADE                     0\n",
       "AGE                       0\n",
       "SKILL                     0\n",
       "STARCOLL                  0\n",
       "NUMOFF                    0\n",
       "POS                       0\n",
       "HEIGHT_IN                 0\n",
       "WEIGHT_LBS                0\n",
       "COLLDIST_MI               0\n",
       "NILVAL_LONG_USD           0\n",
       "INSTA_LONG                0\n",
       "TWIT_LONG                 0\n",
       "TIK_LONG                  0\n",
       "TOT_FOL                   0\n",
       "RECRUIT_YEAR              0\n",
       "EXP_MONTHS                0\n",
       "EXP_YEARS                 0\n",
       "institution_name_short    0\n",
       "ClassificationCode        0\n",
       "REV_MEN                   0\n",
       "EXP_MEN                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_football.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                       object\n",
       "GRADE                     float64\n",
       "AGE                       float64\n",
       "SKILL                     float64\n",
       "STARCOLL                   object\n",
       "NUMOFF                    float64\n",
       "POS                       float64\n",
       "HEIGHT_IN                 float64\n",
       "WEIGHT_LBS                float64\n",
       "COLLDIST_MI               float64\n",
       "NILVAL_LONG_USD           float64\n",
       "INSTA_LONG                float64\n",
       "TWIT_LONG                 float64\n",
       "TIK_LONG                  float64\n",
       "TOT_FOL                   float64\n",
       "RECRUIT_YEAR              float64\n",
       "EXP_MONTHS                float64\n",
       "EXP_YEARS                 float64\n",
       "institution_name_short     object\n",
       "ClassificationCode        float64\n",
       "REV_MEN                   float64\n",
       "EXP_MEN                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_football.shape\n",
    "df_football.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract feature and target arrays\n",
    "X, y = df_football.drop('NILVAL_LONG_USD', axis=1), df_football[['NILVAL_LONG_USD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has 3 categorical featurs (NAME, STARCOLL, institution_name_short). XGBoost has the ability to internally deal with categoricals.Enable this feature by castingthe categorical columns into Pandas category data type (by default, they are treated as text columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text features\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Convert to Pandas category\n",
    "for col in cats:\n",
    "   X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      category\n",
       "GRADE                      float64\n",
       "AGE                        float64\n",
       "SKILL                      float64\n",
       "STARCOLL                  category\n",
       "NUMOFF                     float64\n",
       "POS                        float64\n",
       "HEIGHT_IN                  float64\n",
       "WEIGHT_LBS                 float64\n",
       "COLLDIST_MI                float64\n",
       "INSTA_LONG                 float64\n",
       "TWIT_LONG                  float64\n",
       "TIK_LONG                   float64\n",
       "TOT_FOL                    float64\n",
       "RECRUIT_YEAR               float64\n",
       "EXP_MONTHS                 float64\n",
       "EXP_YEARS                  float64\n",
       "institution_name_short    category\n",
       "ClassificationCode         float64\n",
       "REV_MEN                    float64\n",
       "EXP_MEN                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into test and train (0.20 test)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost comes with its own class for storing datasets called DMatrix. It is a highly optimized class for memory and speed. That's why converting datasets into this format is a requirement for the native XGBoost API. Native API of XGBoost contains some excellent features that Scikit-Learn API doesn’t support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create regression matrices\n",
    "#class accepts both the training features and the labels- enable_categorical = True)\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a value for the objective parameter- RMSE, minimizes the square root of the squared sum of the differences between actual and predicted values. Objective functions and specified hyperparameters specified in params dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_boost_round =  number of boosting rounds. Hyperparameter to be tuned. Initally set to 100.\n",
    "#training dataset = dtrain_reg\n",
    "#function trains the XGBoost regression model with the specified hyperparameters and returns the trained model.\n",
    "#tree booster always outperforms the linear booster (which israrely used)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "num_boost_round = 100\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation** During boosting rounds, the model object has learned all the patterns of the training set. Perform testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dtest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the base model: 207216.846\n",
      "MAE of the base model: 149360.500\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"MAE of the base model: {mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Validation Sets during Training** https://www.datacamp.com/tutorial/xgboost-in-python\n",
    "Use evaluation arrays that allow us to see model performance as it gets improved incrementally across boosting rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:232839.44396\tvalidation-rmse:179583.05099\n",
      "[10]\ttrain-rmse:38468.93716\tvalidation-rmse:157641.42563\n",
      "[20]\ttrain-rmse:10827.30977\tvalidation-rmse:156480.07296\n",
      "[30]\ttrain-rmse:4045.93682\tvalidation-rmse:156004.48672\n",
      "[40]\ttrain-rmse:1738.29290\tvalidation-rmse:155904.02713\n",
      "[50]\ttrain-rmse:720.54474\tvalidation-rmse:155875.09063\n",
      "[60]\ttrain-rmse:281.44186\tvalidation-rmse:155894.99480\n",
      "[70]\ttrain-rmse:93.87351\tvalidation-rmse:155897.54192\n",
      "[80]\ttrain-rmse:36.37500\tvalidation-rmse:155898.30804\n",
      "[90]\ttrain-rmse:12.46337\tvalidation-rmse:155897.71815\n",
      "[99]\ttrain-rmse:4.82532\tvalidation-rmse:155897.59860\n"
     ]
    }
   ],
   "source": [
    "#set parameters again\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "num_boost_round = 100\n",
    "\n",
    "#create list of two tupleshat each contain two elements. \n",
    "# #The first element is the array for the model to evaluate.\n",
    "#The second is the array’s name.\n",
    "\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "#Pass array to evals parameter of xgb.train to see model boosting performance after each round\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   evals=evals,\n",
    "   verbose_eval=10 # Every ten rounds   #forces XGBoost to print performance updates every vebose_eval rounds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE reduced from 179583 to 155897\n",
    "Trying 5000 rounds with verbosity 250\n",
    "Reaches training and validation loss before 500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:179583.05099\ttrain-rmse:232839.44396\n",
      "[250]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[500]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[750]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[1000]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[1250]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[1500]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[1750]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[2000]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[2250]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[2500]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[2750]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[3000]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[3250]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[3500]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[3750]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[4000]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[4250]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[4500]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[4750]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[4999]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n"
     ]
    }
   ],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "num_boost_round = 5000\n",
    "\n",
    "evals = [(dtest_reg, \"validation\"), (dtrain_reg, \"train\")]\n",
    "\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   evals=evals,\n",
    "   verbose_eval=250\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Early Stopping** Forces XGBoost to watch the validation loss, and if it stops improving for a specified number of rounds, it automatically stops training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:179583.05099\ttrain-rmse:232839.44396\n",
      "[50]\tvalidation-rmse:155875.09063\ttrain-rmse:720.54474\n",
      "[100]\tvalidation-rmse:155897.60612\ttrain-rmse:4.30692\n",
      "[150]\tvalidation-rmse:155897.57014\ttrain-rmse:0.04143\n",
      "[200]\tvalidation-rmse:155897.57030\ttrain-rmse:0.02512\n",
      "[250]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n",
      "[269]\tvalidation-rmse:155897.56961\ttrain-rmse:0.02398\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   evals=evals,\n",
    "   verbose_eval=50,\n",
    "   early_stopping_rounds=50  #Activiate early stopping\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training stopped after Round 269. <br>\n",
    "**Perform K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "n = 1000\n",
    "\n",
    "results = xgb.cv(\n",
    "   params, \n",
    "   dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   nfold=5,\n",
    "   early_stopping_rounds=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232827.836324</td>\n",
       "      <td>25911.987976</td>\n",
       "      <td>262270.231396</td>\n",
       "      <td>111125.625739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183404.741051</td>\n",
       "      <td>22019.227188</td>\n",
       "      <td>250053.457446</td>\n",
       "      <td>111581.256171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147169.076968</td>\n",
       "      <td>18985.128355</td>\n",
       "      <td>241413.810697</td>\n",
       "      <td>112692.567455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119875.037706</td>\n",
       "      <td>16741.528216</td>\n",
       "      <td>236047.145392</td>\n",
       "      <td>113908.354654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98916.861318</td>\n",
       "      <td>14603.766735</td>\n",
       "      <td>232304.709498</td>\n",
       "      <td>114910.477273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0    232827.836324    25911.987976   262270.231396  111125.625739\n",
       "1    183404.741051    22019.227188   250053.457446  111581.256171\n",
       "2    147169.076968    18985.128355   241413.810697  112692.567455\n",
       "3    119875.037706    16741.528216   236047.145392  113908.354654\n",
       "4     98916.861318    14603.766735   232304.709498  114910.477273"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df containing each folds results\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE of the base model: 225010.393\n"
     ]
    }
   ],
   "source": [
    "#find the best score by taking the minimum of the test-rmse-mean column\n",
    "best_rmse = results['test-rmse-mean'].min()\n",
    "\n",
    "best_rmse\n",
    "print(f\"Best RMSE of the base model: {best_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance** Which features are most influential in making NIL prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ea192d6b08>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(model, max_num_features=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:120758.94419\n",
      "[1]\tTest-mae:102986.61452\n",
      "[2]\tTest-mae:92342.13903\n",
      "[3]\tTest-mae:87560.44415\n",
      "[4]\tTest-mae:84765.73261\n",
      "[5]\tTest-mae:83849.20451\n",
      "[6]\tTest-mae:81800.84306\n",
      "[7]\tTest-mae:81523.91439\n",
      "[8]\tTest-mae:81109.92638\n",
      "[9]\tTest-mae:80426.51620\n",
      "[10]\tTest-mae:80892.42851\n",
      "[11]\tTest-mae:80176.35470\n",
      "[12]\tTest-mae:79998.18066\n",
      "[13]\tTest-mae:80324.95655\n",
      "[14]\tTest-mae:80042.98584\n",
      "[15]\tTest-mae:79863.27790\n",
      "[16]\tTest-mae:79752.87190\n",
      "[17]\tTest-mae:79749.15833\n",
      "[18]\tTest-mae:79769.18335\n",
      "[19]\tTest-mae:79687.04254\n",
      "[20]\tTest-mae:79418.33087\n",
      "[21]\tTest-mae:79378.42912\n",
      "[22]\tTest-mae:79398.98499\n",
      "[23]\tTest-mae:79417.32752\n",
      "[24]\tTest-mae:79280.81567\n",
      "[25]\tTest-mae:79296.20053\n",
      "[26]\tTest-mae:79191.39453\n",
      "[27]\tTest-mae:79137.34066\n",
      "[28]\tTest-mae:79177.34134\n",
      "[29]\tTest-mae:79169.39510\n",
      "[30]\tTest-mae:79154.25652\n",
      "[31]\tTest-mae:79207.96480\n",
      "[32]\tTest-mae:79178.61975\n",
      "[33]\tTest-mae:79212.36350\n",
      "[34]\tTest-mae:79182.71750\n",
      "[35]\tTest-mae:79148.63687\n",
      "[36]\tTest-mae:79120.81106\n",
      "[37]\tTest-mae:79100.27339\n",
      "[38]\tTest-mae:79077.06931\n",
      "[39]\tTest-mae:79094.76908\n",
      "[40]\tTest-mae:79070.87285\n",
      "[41]\tTest-mae:79064.95972\n",
      "[42]\tTest-mae:79108.59830\n",
      "[43]\tTest-mae:79076.58459\n",
      "[44]\tTest-mae:79071.41130\n",
      "[45]\tTest-mae:79089.38789\n",
      "[46]\tTest-mae:79072.32255\n",
      "[47]\tTest-mae:79068.59176\n",
      "[48]\tTest-mae:79061.30781\n",
      "[49]\tTest-mae:79067.23265\n",
      "[50]\tTest-mae:79054.72480\n",
      "[51]\tTest-mae:79061.38396\n",
      "[52]\tTest-mae:79063.00747\n",
      "[53]\tTest-mae:79073.65759\n",
      "[54]\tTest-mae:79074.32297\n",
      "[55]\tTest-mae:79068.55564\n",
      "[56]\tTest-mae:79071.70309\n",
      "[57]\tTest-mae:79067.35717\n",
      "[58]\tTest-mae:79068.67316\n",
      "[59]\tTest-mae:79075.64084\n",
      "Best MAE: 79054.72 with 51 rounds\n"
     ]
    }
   ],
   "source": [
    "# # Define hyperparameters\n",
    "# params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "num_boost_round = 999\n",
    "params['eval_metric'] = \"mae\"\n",
    "\n",
    "# evals = [(dtest_reg, \"validation\"), (dtrain_reg, \"train\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    params = params,\n",
    "    dtrain =dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    # evals=evals,\n",
    "    evals=[(dtest_reg, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "preds = model.predict(dtest_reg)\n",
    "\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline was:<br>RMSE of the base model: 206653.627\n",
    "<br> MAE of the base model: 148719.134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233375.894167</td>\n",
       "      <td>21465.654955</td>\n",
       "      <td>115027.575739</td>\n",
       "      <td>3256.325344</td>\n",
       "      <td>265156.590260</td>\n",
       "      <td>99862.087315</td>\n",
       "      <td>134229.264548</td>\n",
       "      <td>18067.766788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184047.401386</td>\n",
       "      <td>18273.504240</td>\n",
       "      <td>83184.071831</td>\n",
       "      <td>2447.805042</td>\n",
       "      <td>252444.576054</td>\n",
       "      <td>99102.376017</td>\n",
       "      <td>116960.484692</td>\n",
       "      <td>17378.011929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147257.573847</td>\n",
       "      <td>16934.915284</td>\n",
       "      <td>60970.792275</td>\n",
       "      <td>1911.224145</td>\n",
       "      <td>244787.424096</td>\n",
       "      <td>98428.350444</td>\n",
       "      <td>107380.213691</td>\n",
       "      <td>18218.110936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120286.853647</td>\n",
       "      <td>15580.974289</td>\n",
       "      <td>45914.256648</td>\n",
       "      <td>1635.560174</td>\n",
       "      <td>239507.851095</td>\n",
       "      <td>98882.362647</td>\n",
       "      <td>100932.462206</td>\n",
       "      <td>19708.226760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99186.819600</td>\n",
       "      <td>14487.346131</td>\n",
       "      <td>36219.527199</td>\n",
       "      <td>1597.516132</td>\n",
       "      <td>236227.383115</td>\n",
       "      <td>98975.690162</td>\n",
       "      <td>96957.236405</td>\n",
       "      <td>19769.511561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82454.353493</td>\n",
       "      <td>13085.026749</td>\n",
       "      <td>29558.627867</td>\n",
       "      <td>1643.650633</td>\n",
       "      <td>235437.634251</td>\n",
       "      <td>99626.395471</td>\n",
       "      <td>94278.594991</td>\n",
       "      <td>20432.309038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69183.103644</td>\n",
       "      <td>11838.523378</td>\n",
       "      <td>24868.496392</td>\n",
       "      <td>1958.404476</td>\n",
       "      <td>235629.860697</td>\n",
       "      <td>100674.537425</td>\n",
       "      <td>92943.190459</td>\n",
       "      <td>21325.942442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58297.927380</td>\n",
       "      <td>10433.727291</td>\n",
       "      <td>21171.406330</td>\n",
       "      <td>1784.423965</td>\n",
       "      <td>236439.026935</td>\n",
       "      <td>101650.548979</td>\n",
       "      <td>92522.231822</td>\n",
       "      <td>21828.204289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49684.722419</td>\n",
       "      <td>9190.683904</td>\n",
       "      <td>18616.192004</td>\n",
       "      <td>1775.498671</td>\n",
       "      <td>237132.209527</td>\n",
       "      <td>102524.519366</td>\n",
       "      <td>91758.460705</td>\n",
       "      <td>22189.354034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42052.805550</td>\n",
       "      <td>8152.731612</td>\n",
       "      <td>16049.496344</td>\n",
       "      <td>1764.726049</td>\n",
       "      <td>238277.295945</td>\n",
       "      <td>103357.001734</td>\n",
       "      <td>91491.083632</td>\n",
       "      <td>22188.547014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36108.668802</td>\n",
       "      <td>6923.608381</td>\n",
       "      <td>14310.158660</td>\n",
       "      <td>1630.836419</td>\n",
       "      <td>239244.305493</td>\n",
       "      <td>104187.956091</td>\n",
       "      <td>91273.061297</td>\n",
       "      <td>22454.381655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31287.698302</td>\n",
       "      <td>5896.512009</td>\n",
       "      <td>12968.802608</td>\n",
       "      <td>1592.363445</td>\n",
       "      <td>240283.862950</td>\n",
       "      <td>104965.352029</td>\n",
       "      <td>91250.333601</td>\n",
       "      <td>22737.839971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27214.229905</td>\n",
       "      <td>4907.490754</td>\n",
       "      <td>11755.805158</td>\n",
       "      <td>1264.133418</td>\n",
       "      <td>241222.126133</td>\n",
       "      <td>105816.135163</td>\n",
       "      <td>91305.327379</td>\n",
       "      <td>23085.154475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23623.254886</td>\n",
       "      <td>4026.100930</td>\n",
       "      <td>10517.341872</td>\n",
       "      <td>1107.055564</td>\n",
       "      <td>241908.596206</td>\n",
       "      <td>106579.888716</td>\n",
       "      <td>91139.854776</td>\n",
       "      <td>23169.482870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  train-mae-mean  train-mae-std  \\\n",
       "0     233375.894167    21465.654955   115027.575739    3256.325344   \n",
       "1     184047.401386    18273.504240    83184.071831    2447.805042   \n",
       "2     147257.573847    16934.915284    60970.792275    1911.224145   \n",
       "3     120286.853647    15580.974289    45914.256648    1635.560174   \n",
       "4      99186.819600    14487.346131    36219.527199    1597.516132   \n",
       "5      82454.353493    13085.026749    29558.627867    1643.650633   \n",
       "6      69183.103644    11838.523378    24868.496392    1958.404476   \n",
       "7      58297.927380    10433.727291    21171.406330    1784.423965   \n",
       "8      49684.722419     9190.683904    18616.192004    1775.498671   \n",
       "9      42052.805550     8152.731612    16049.496344    1764.726049   \n",
       "10     36108.668802     6923.608381    14310.158660    1630.836419   \n",
       "11     31287.698302     5896.512009    12968.802608    1592.363445   \n",
       "12     27214.229905     4907.490754    11755.805158    1264.133418   \n",
       "13     23623.254886     4026.100930    10517.341872    1107.055564   \n",
       "\n",
       "    test-rmse-mean  test-rmse-std  test-mae-mean  test-mae-std  \n",
       "0    265156.590260   99862.087315  134229.264548  18067.766788  \n",
       "1    252444.576054   99102.376017  116960.484692  17378.011929  \n",
       "2    244787.424096   98428.350444  107380.213691  18218.110936  \n",
       "3    239507.851095   98882.362647  100932.462206  19708.226760  \n",
       "4    236227.383115   98975.690162   96957.236405  19769.511561  \n",
       "5    235437.634251   99626.395471   94278.594991  20432.309038  \n",
       "6    235629.860697  100674.537425   92943.190459  21325.942442  \n",
       "7    236439.026935  101650.548979   92522.231822  21828.204289  \n",
       "8    237132.209527  102524.519366   91758.460705  22189.354034  \n",
       "9    238277.295945  103357.001734   91491.083632  22188.547014  \n",
       "10   239244.305493  104187.956091   91273.061297  22454.381655  \n",
       "11   240283.862950  104965.352029   91250.333601  22737.839971  \n",
       "12   241222.126133  105816.135163   91305.327379  23085.154475  \n",
       "13   241908.596206  106579.888716   91139.854776  23169.482870  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation with current parameters\n",
    "# params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae', 'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE CV: 235437.634\n",
      "Best MAE CV: 65414.596\n"
     ]
    }
   ],
   "source": [
    "# best_mae = cv_results['test-mae-mean'].min()\n",
    "# best_mae\n",
    "\n",
    "best_rmse = cv_results['test-rmse-mean'].min()\n",
    "best_rmse\n",
    "print(f\"Best RMSE CV: {best_rmse:.3f}\")\n",
    "print(f\"Best MAE CV: {best_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline was:<br>RMSE of the base model: 206653.627\n",
    "<br> MAE of the base model: 148719.134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMAE 66025.27766862624 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 67020.71357131806 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 65208.85380569308 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE 65086.750317141086 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 66542.18403852104 for 4 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 65823.68037592822 for 6 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE 66232.3709738552 for 6 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 66146.29288366337 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE 65414.59646890471 for 6 rounds\n",
      "Best params: 10, 5, MAE: 65086.750317141086\n"
     ]
    }
   ],
   "source": [
    "#tuning max_depth and min_child_weight\n",
    "'''  max_depth = maximum number of nodes allowed from the root to the farthest leaf of a tree. \n",
    "                Deeper trees can model more complex relationships by adding more nodes, \n",
    "                but as we go deeper,splits become less relevant and are sometimes only due to noise,\n",
    "                causing the model to overfit. \n",
    "                min_child_weight = minimum weight (or number of samples if all samples have a weight of 1) \n",
    "                required in order to create a new node in the tree.\n",
    "                A smaller min_child_weight allows the algorithm to create children that \n",
    "                correspond to fewer samples, thus allowing for more complex trees, \n",
    "                but again, more likely to overfit. '''\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain_reg,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae', 'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "     # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update params\n",
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 65086.750317141086 for 6 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 67097.1855778156 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 64866.98271194308 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 68223.52738242575 for 6 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 66918.26770188738 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 66032.96971689357 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 67432.69890547649 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 68414.73435179456 for 5 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 64560.56417079208 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 66753.6083539604 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 68714.97074566832 for 6 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 69824.62070699257 for 6 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 66006.89182008045 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 66547.23732595917 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 66449.35556157178 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 70193.4445157797 for 6 rounds\n",
      "Best params: 0.8, 1.0, MAE: 64560.56417079208\n"
     ]
    }
   ],
   "source": [
    "#tuning subsample and colsample_bytree\n",
    "'''   Instead of using the whole training set every time, we can build a \n",
    "    tree on slightly different data at each step, \n",
    "    which makes it less likely to overfit to a single sample or feature.\n",
    "\n",
    "subsample =  the fraction of observations (the rows) to subsample at each step. \n",
    "By default it is set to 1 meaning that we use all rows.\n",
    "colsample_bytree = the fraction of features (the columns) to use. \n",
    "By default it is set to 1 meaning that we will use all features    '''\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain_reg,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "        \n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update params\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 0 ns\n",
      "\tMAE 64560.56417079208 for 5 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "Wall time: 0 ns\n",
      "\tMAE 64274.08786355198 for 9 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 0 ns\n",
      "\tMAE 62565.323619275994 for 20 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 0 ns\n",
      "\tMAE 61202.043722926974 for 39 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 0 ns\n",
      "\tMAE 61241.42267172029 for 203 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "Wall time: 0 ns\n",
      "\tMAE 60860.7320621906 for 418 rounds\n",
      "\n",
      "Best params: 0.005, MAE: 60860.7320621906\n"
     ]
    }
   ],
   "source": [
    "#tuning  eta\n",
    "import time\n",
    "\n",
    "'''    eta = controls the learning rate. corresponds to the shrinkage of \n",
    "            the weights associated to features after each round/ defines the amount of \"correction\" \n",
    "            at each step\n",
    "            lower eta makes model more robust to overfitting.\n",
    "            Usually, the lower the learning rate, the best. \n",
    "            With lower eta,  need more boosting rounds, which takes more time to train, \n",
    "            sometimes for only marginal improvements\n",
    "\n",
    "\n",
    "'''\n",
    "time\n",
    "\n",
    "%time \n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # Update parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time \n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain_reg,\n",
    "            num_boost_round=num_boost_round,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['mae'],\n",
    "            early_stopping_rounds=10\n",
    "          )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'eta': 0.005,\n",
       " 'eval_metric': {'mae', 'rmse'},\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 5,\n",
       " 'objective': 'reg:tree',\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final params dictionary\n",
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.005,\n",
    "'eval_metric': {'mae','rmse'},\n",
    "'max_depth': 10,\n",
    "'min_child_weight': 5,\n",
    "'objective': 'reg:tree',\n",
    "'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model with new params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:146222.73493\n",
      "[1]\tTest-mae:145530.41718\n",
      "[2]\tTest-mae:144825.36297\n",
      "[3]\tTest-mae:144115.44565\n",
      "[4]\tTest-mae:143406.69053\n",
      "[5]\tTest-mae:142635.51592\n",
      "[6]\tTest-mae:141928.63962\n",
      "[7]\tTest-mae:141257.88331\n",
      "[8]\tTest-mae:140453.04326\n",
      "[9]\tTest-mae:139735.76603\n",
      "[10]\tTest-mae:139123.43281\n",
      "[11]\tTest-mae:138485.60703\n",
      "[12]\tTest-mae:137836.73694\n",
      "[13]\tTest-mae:137140.64220\n",
      "[14]\tTest-mae:136508.91795\n",
      "[15]\tTest-mae:135810.41610\n",
      "[16]\tTest-mae:135130.49435\n",
      "[17]\tTest-mae:134462.91789\n",
      "[18]\tTest-mae:133763.78533\n",
      "[19]\tTest-mae:133081.16332\n",
      "[20]\tTest-mae:132406.79371\n",
      "[21]\tTest-mae:131787.00684\n",
      "[22]\tTest-mae:131147.76709\n",
      "[23]\tTest-mae:130450.14225\n",
      "[24]\tTest-mae:129800.02321\n",
      "[25]\tTest-mae:129096.22162\n",
      "[26]\tTest-mae:128528.46608\n",
      "[27]\tTest-mae:127926.26507\n",
      "[28]\tTest-mae:127320.50286\n",
      "[29]\tTest-mae:126611.98655\n",
      "[30]\tTest-mae:125994.01779\n",
      "[31]\tTest-mae:125360.20879\n",
      "[32]\tTest-mae:124733.69436\n",
      "[33]\tTest-mae:124095.33561\n",
      "[34]\tTest-mae:123506.39649\n",
      "[35]\tTest-mae:122838.30280\n",
      "[36]\tTest-mae:122207.29581\n",
      "[37]\tTest-mae:121599.71832\n",
      "[38]\tTest-mae:120966.37488\n",
      "[39]\tTest-mae:120374.92470\n",
      "[40]\tTest-mae:119745.96829\n",
      "[41]\tTest-mae:119128.26774\n",
      "[42]\tTest-mae:118505.87935\n",
      "[43]\tTest-mae:117956.14192\n",
      "[44]\tTest-mae:117383.45141\n",
      "[45]\tTest-mae:116745.98549\n",
      "[46]\tTest-mae:116156.38531\n",
      "[47]\tTest-mae:115592.96955\n",
      "[48]\tTest-mae:115053.81096\n",
      "[49]\tTest-mae:114428.63998\n",
      "[50]\tTest-mae:113907.19676\n",
      "[51]\tTest-mae:113269.91508\n",
      "[52]\tTest-mae:112739.83324\n",
      "[53]\tTest-mae:112236.75646\n",
      "[54]\tTest-mae:111705.68455\n",
      "[55]\tTest-mae:111177.27109\n",
      "[56]\tTest-mae:110617.30311\n",
      "[57]\tTest-mae:110090.28784\n",
      "[58]\tTest-mae:109630.50090\n",
      "[59]\tTest-mae:109090.78369\n",
      "[60]\tTest-mae:108587.69584\n",
      "[61]\tTest-mae:108100.07061\n",
      "[62]\tTest-mae:107594.72991\n",
      "[63]\tTest-mae:107087.92457\n",
      "[64]\tTest-mae:106533.61561\n",
      "[65]\tTest-mae:106115.99131\n",
      "[66]\tTest-mae:105646.87129\n",
      "[67]\tTest-mae:105102.75730\n",
      "[68]\tTest-mae:104658.48512\n",
      "[69]\tTest-mae:104237.31909\n",
      "[70]\tTest-mae:103805.14461\n",
      "[71]\tTest-mae:103325.37197\n",
      "[72]\tTest-mae:102907.08103\n",
      "[73]\tTest-mae:102417.69409\n",
      "[74]\tTest-mae:102023.99917\n",
      "[75]\tTest-mae:101563.78623\n",
      "[76]\tTest-mae:101167.38335\n",
      "[77]\tTest-mae:100657.47242\n",
      "[78]\tTest-mae:100194.48474\n",
      "[79]\tTest-mae:99752.31858\n",
      "[80]\tTest-mae:99345.81753\n",
      "[81]\tTest-mae:98857.35962\n",
      "[82]\tTest-mae:98457.30734\n",
      "[83]\tTest-mae:98074.06999\n",
      "[84]\tTest-mae:97646.49796\n",
      "[85]\tTest-mae:97212.04572\n",
      "[86]\tTest-mae:96795.93898\n",
      "[87]\tTest-mae:96419.67711\n",
      "[88]\tTest-mae:96014.89784\n",
      "[89]\tTest-mae:95609.26605\n",
      "[90]\tTest-mae:95209.04999\n",
      "[91]\tTest-mae:94823.35235\n",
      "[92]\tTest-mae:94452.98597\n",
      "[93]\tTest-mae:94081.76403\n",
      "[94]\tTest-mae:93727.96447\n",
      "[95]\tTest-mae:93310.53220\n",
      "[96]\tTest-mae:92929.64578\n",
      "[97]\tTest-mae:92546.10703\n",
      "[98]\tTest-mae:92195.18515\n",
      "[99]\tTest-mae:91840.71216\n",
      "[100]\tTest-mae:91440.48974\n",
      "[101]\tTest-mae:91042.91541\n",
      "[102]\tTest-mae:90643.42906\n",
      "[103]\tTest-mae:90264.66653\n",
      "[104]\tTest-mae:89862.39596\n",
      "[105]\tTest-mae:89469.75318\n",
      "[106]\tTest-mae:89106.10922\n",
      "[107]\tTest-mae:88762.83069\n",
      "[108]\tTest-mae:88442.76799\n",
      "[109]\tTest-mae:88060.20529\n",
      "[110]\tTest-mae:87708.80061\n",
      "[111]\tTest-mae:87361.42630\n",
      "[112]\tTest-mae:87017.36896\n",
      "[113]\tTest-mae:86703.94494\n",
      "[114]\tTest-mae:86424.35643\n",
      "[115]\tTest-mae:86097.59122\n",
      "[116]\tTest-mae:85802.85031\n",
      "[117]\tTest-mae:85523.57070\n",
      "[118]\tTest-mae:85234.04828\n",
      "[119]\tTest-mae:84902.89377\n",
      "[120]\tTest-mae:84615.00412\n",
      "[121]\tTest-mae:84301.74302\n",
      "[122]\tTest-mae:84007.77552\n",
      "[123]\tTest-mae:83687.82951\n",
      "[124]\tTest-mae:83401.59111\n",
      "[125]\tTest-mae:83106.18475\n",
      "[126]\tTest-mae:82845.13274\n",
      "[127]\tTest-mae:82530.81089\n",
      "[128]\tTest-mae:82204.43625\n",
      "[129]\tTest-mae:81868.90418\n",
      "[130]\tTest-mae:81593.75514\n",
      "[131]\tTest-mae:81281.10539\n",
      "[132]\tTest-mae:81026.17969\n",
      "[133]\tTest-mae:80763.00405\n",
      "[134]\tTest-mae:80448.42016\n",
      "[135]\tTest-mae:80152.97523\n",
      "[136]\tTest-mae:79848.68122\n",
      "[137]\tTest-mae:79579.50025\n",
      "[138]\tTest-mae:79309.12200\n",
      "[139]\tTest-mae:79002.36930\n",
      "[140]\tTest-mae:78751.15651\n",
      "[141]\tTest-mae:78456.87106\n",
      "[142]\tTest-mae:78135.13903\n",
      "[143]\tTest-mae:77818.14192\n",
      "[144]\tTest-mae:77569.66928\n",
      "[145]\tTest-mae:77305.82090\n",
      "[146]\tTest-mae:77036.59966\n",
      "[147]\tTest-mae:76761.36401\n",
      "[148]\tTest-mae:76503.74160\n",
      "[149]\tTest-mae:76254.94601\n",
      "[150]\tTest-mae:75976.46733\n",
      "[151]\tTest-mae:75719.84069\n",
      "[152]\tTest-mae:75458.12404\n",
      "[153]\tTest-mae:75208.93466\n",
      "[154]\tTest-mae:74943.36762\n",
      "[155]\tTest-mae:74629.87310\n",
      "[156]\tTest-mae:74358.65017\n",
      "[157]\tTest-mae:74129.44618\n",
      "[158]\tTest-mae:73895.23774\n",
      "[159]\tTest-mae:73652.33050\n",
      "[160]\tTest-mae:73411.34264\n",
      "[161]\tTest-mae:73201.51394\n",
      "[162]\tTest-mae:72948.85775\n",
      "[163]\tTest-mae:72711.50014\n",
      "[164]\tTest-mae:72469.71971\n",
      "[165]\tTest-mae:72240.37481\n",
      "[166]\tTest-mae:71991.65210\n",
      "[167]\tTest-mae:71731.99724\n",
      "[168]\tTest-mae:71486.20164\n",
      "[169]\tTest-mae:71240.37704\n",
      "[170]\tTest-mae:70995.33937\n",
      "[171]\tTest-mae:70803.27449\n",
      "[172]\tTest-mae:70544.09641\n",
      "[173]\tTest-mae:70368.82674\n",
      "[174]\tTest-mae:70128.11649\n",
      "[175]\tTest-mae:69865.20133\n",
      "[176]\tTest-mae:69641.84539\n",
      "[177]\tTest-mae:69415.09424\n",
      "[178]\tTest-mae:69195.11957\n",
      "[179]\tTest-mae:68962.99829\n",
      "[180]\tTest-mae:68730.74066\n",
      "[181]\tTest-mae:68564.08391\n",
      "[182]\tTest-mae:68329.17858\n",
      "[183]\tTest-mae:68129.66328\n",
      "[184]\tTest-mae:67869.29334\n",
      "[185]\tTest-mae:67626.79085\n",
      "[186]\tTest-mae:67413.05742\n",
      "[187]\tTest-mae:67229.28040\n",
      "[188]\tTest-mae:67053.41155\n",
      "[189]\tTest-mae:66835.97808\n",
      "[190]\tTest-mae:66667.04416\n",
      "[191]\tTest-mae:66415.03576\n",
      "[192]\tTest-mae:66171.61895\n",
      "[193]\tTest-mae:65989.26959\n",
      "[194]\tTest-mae:65798.75154\n",
      "[195]\tTest-mae:65598.13409\n",
      "[196]\tTest-mae:65425.15580\n",
      "[197]\tTest-mae:65240.65798\n",
      "[198]\tTest-mae:65050.19133\n",
      "[199]\tTest-mae:64865.05132\n",
      "[200]\tTest-mae:64724.27592\n",
      "[201]\tTest-mae:64574.23484\n",
      "[202]\tTest-mae:64417.76160\n",
      "[203]\tTest-mae:64268.82939\n",
      "[204]\tTest-mae:64093.79244\n",
      "[205]\tTest-mae:63959.42504\n",
      "[206]\tTest-mae:63774.25225\n",
      "[207]\tTest-mae:63601.48593\n",
      "[208]\tTest-mae:63432.14936\n",
      "[209]\tTest-mae:63282.79663\n",
      "[210]\tTest-mae:63132.58767\n",
      "[211]\tTest-mae:62968.88465\n",
      "[212]\tTest-mae:62809.76377\n",
      "[213]\tTest-mae:62607.69886\n",
      "[214]\tTest-mae:62477.80203\n",
      "[215]\tTest-mae:62347.65483\n",
      "[216]\tTest-mae:62189.06594\n",
      "[217]\tTest-mae:62055.96211\n",
      "[218]\tTest-mae:61928.84750\n",
      "[219]\tTest-mae:61793.26348\n",
      "[220]\tTest-mae:61660.21727\n",
      "[221]\tTest-mae:61501.33853\n",
      "[222]\tTest-mae:61379.91477\n",
      "[223]\tTest-mae:61236.25434\n",
      "[224]\tTest-mae:61066.99443\n",
      "[225]\tTest-mae:60883.84579\n",
      "[226]\tTest-mae:60754.12946\n",
      "[227]\tTest-mae:60608.72931\n",
      "[228]\tTest-mae:60453.11294\n",
      "[229]\tTest-mae:60335.93475\n",
      "[230]\tTest-mae:60175.12469\n",
      "[231]\tTest-mae:60069.56196\n",
      "[232]\tTest-mae:59868.61892\n",
      "[233]\tTest-mae:59731.66184\n",
      "[234]\tTest-mae:59600.02328\n",
      "[235]\tTest-mae:59461.86645\n",
      "[236]\tTest-mae:59381.80010\n",
      "[237]\tTest-mae:59256.30044\n",
      "[238]\tTest-mae:59138.45260\n",
      "[239]\tTest-mae:58967.87960\n",
      "[240]\tTest-mae:58855.78573\n",
      "[241]\tTest-mae:58743.08611\n",
      "[242]\tTest-mae:58592.29772\n",
      "[243]\tTest-mae:58491.77569\n",
      "[244]\tTest-mae:58340.80473\n",
      "[245]\tTest-mae:58217.95916\n",
      "[246]\tTest-mae:58064.82845\n",
      "[247]\tTest-mae:57898.80158\n",
      "[248]\tTest-mae:57767.57041\n",
      "[249]\tTest-mae:57640.54515\n",
      "[250]\tTest-mae:57532.95953\n",
      "[251]\tTest-mae:57451.58322\n",
      "[252]\tTest-mae:57311.77501\n",
      "[253]\tTest-mae:57207.31529\n",
      "[254]\tTest-mae:57105.18098\n",
      "[255]\tTest-mae:57008.05972\n",
      "[256]\tTest-mae:56870.09670\n",
      "[257]\tTest-mae:56765.73865\n",
      "[258]\tTest-mae:56631.64569\n",
      "[259]\tTest-mae:56555.07667\n",
      "[260]\tTest-mae:56480.39524\n",
      "[261]\tTest-mae:56379.78043\n",
      "[262]\tTest-mae:56269.56441\n",
      "[263]\tTest-mae:56163.35124\n",
      "[264]\tTest-mae:56053.05183\n",
      "[265]\tTest-mae:55955.54024\n",
      "[266]\tTest-mae:55890.48564\n",
      "[267]\tTest-mae:55782.58070\n",
      "[268]\tTest-mae:55716.13269\n",
      "[269]\tTest-mae:55563.81063\n",
      "[270]\tTest-mae:55394.46625\n",
      "[271]\tTest-mae:55323.69553\n",
      "[272]\tTest-mae:55250.87730\n",
      "[273]\tTest-mae:55106.62040\n",
      "[274]\tTest-mae:54959.16030\n",
      "[275]\tTest-mae:54885.07728\n",
      "[276]\tTest-mae:54790.32070\n",
      "[277]\tTest-mae:54659.24616\n",
      "[278]\tTest-mae:54606.13201\n",
      "[279]\tTest-mae:54523.42841\n",
      "[280]\tTest-mae:54470.62656\n",
      "[281]\tTest-mae:54393.31377\n",
      "[282]\tTest-mae:54297.90875\n",
      "[283]\tTest-mae:54233.79105\n",
      "[284]\tTest-mae:54142.19419\n",
      "[285]\tTest-mae:54063.63534\n",
      "[286]\tTest-mae:53972.22094\n",
      "[287]\tTest-mae:53902.57556\n",
      "[288]\tTest-mae:53817.20703\n",
      "[289]\tTest-mae:53687.58351\n",
      "[290]\tTest-mae:53603.26119\n",
      "[291]\tTest-mae:53527.26261\n",
      "[292]\tTest-mae:53462.95648\n",
      "[293]\tTest-mae:53368.15532\n",
      "[294]\tTest-mae:53295.40063\n",
      "[295]\tTest-mae:53189.17987\n",
      "[296]\tTest-mae:53120.41295\n",
      "[297]\tTest-mae:53016.89594\n",
      "[298]\tTest-mae:52944.32621\n",
      "[299]\tTest-mae:52875.69351\n",
      "[300]\tTest-mae:52752.29541\n",
      "[301]\tTest-mae:52687.85968\n",
      "[302]\tTest-mae:52643.96140\n",
      "[303]\tTest-mae:52559.61764\n",
      "[304]\tTest-mae:52462.80893\n",
      "[305]\tTest-mae:52349.25733\n",
      "[306]\tTest-mae:52294.68631\n",
      "[307]\tTest-mae:52202.14936\n",
      "[308]\tTest-mae:52170.80682\n",
      "[309]\tTest-mae:52091.40728\n",
      "[310]\tTest-mae:52043.60206\n",
      "[311]\tTest-mae:51988.80447\n",
      "[312]\tTest-mae:51915.61408\n",
      "[313]\tTest-mae:51841.70354\n",
      "[314]\tTest-mae:51814.37796\n",
      "[315]\tTest-mae:51757.90241\n",
      "[316]\tTest-mae:51723.21239\n",
      "[317]\tTest-mae:51616.43795\n",
      "[318]\tTest-mae:51537.96061\n",
      "[319]\tTest-mae:51465.23467\n",
      "[320]\tTest-mae:51442.17439\n",
      "[321]\tTest-mae:51378.22031\n",
      "[322]\tTest-mae:51336.18992\n",
      "[323]\tTest-mae:51255.44749\n",
      "[324]\tTest-mae:51206.66235\n",
      "[325]\tTest-mae:51128.71281\n",
      "[326]\tTest-mae:51089.61660\n",
      "[327]\tTest-mae:51016.65915\n",
      "[328]\tTest-mae:50961.59336\n",
      "[329]\tTest-mae:50916.64154\n",
      "[330]\tTest-mae:50872.75914\n",
      "[331]\tTest-mae:50821.98366\n",
      "[332]\tTest-mae:50773.67927\n",
      "[333]\tTest-mae:50729.71450\n",
      "[334]\tTest-mae:50654.54050\n",
      "[335]\tTest-mae:50633.02419\n",
      "[336]\tTest-mae:50622.87333\n",
      "[337]\tTest-mae:50577.72425\n",
      "[338]\tTest-mae:50520.63575\n",
      "[339]\tTest-mae:50553.80509\n",
      "[340]\tTest-mae:50519.57749\n",
      "[341]\tTest-mae:50450.91676\n",
      "[342]\tTest-mae:50414.93542\n",
      "[343]\tTest-mae:50363.22744\n",
      "[344]\tTest-mae:50321.11351\n",
      "[345]\tTest-mae:50256.07630\n",
      "[346]\tTest-mae:50232.25746\n",
      "[347]\tTest-mae:50184.18316\n",
      "[348]\tTest-mae:50121.43135\n",
      "[349]\tTest-mae:50083.48783\n",
      "[350]\tTest-mae:50040.54698\n",
      "[351]\tTest-mae:50017.33717\n",
      "[352]\tTest-mae:49969.28584\n",
      "[353]\tTest-mae:49924.29491\n",
      "[354]\tTest-mae:49893.54586\n",
      "[355]\tTest-mae:49824.01053\n",
      "[356]\tTest-mae:49816.18577\n",
      "[357]\tTest-mae:49763.43943\n",
      "[358]\tTest-mae:49719.96867\n",
      "[359]\tTest-mae:49693.95334\n",
      "[360]\tTest-mae:49637.76959\n",
      "[361]\tTest-mae:49605.01303\n",
      "[362]\tTest-mae:49567.65307\n",
      "[363]\tTest-mae:49544.49358\n",
      "[364]\tTest-mae:49542.93887\n",
      "[365]\tTest-mae:49489.68484\n",
      "[366]\tTest-mae:49465.46332\n",
      "[367]\tTest-mae:49424.35403\n",
      "[368]\tTest-mae:49398.79697\n",
      "[369]\tTest-mae:49449.07081\n",
      "[370]\tTest-mae:49412.85283\n",
      "[371]\tTest-mae:49406.72664\n",
      "[372]\tTest-mae:49396.61859\n",
      "[373]\tTest-mae:49361.24024\n",
      "[374]\tTest-mae:49322.25449\n",
      "[375]\tTest-mae:49300.61927\n",
      "[376]\tTest-mae:49283.72758\n",
      "[377]\tTest-mae:49256.77645\n",
      "[378]\tTest-mae:49231.51214\n",
      "[379]\tTest-mae:49199.37586\n",
      "[380]\tTest-mae:49145.26814\n",
      "[381]\tTest-mae:49169.02841\n",
      "[382]\tTest-mae:49170.13135\n",
      "[383]\tTest-mae:49097.11703\n",
      "[384]\tTest-mae:49066.85564\n",
      "[385]\tTest-mae:49062.15265\n",
      "[386]\tTest-mae:49030.46489\n",
      "[387]\tTest-mae:49021.83178\n",
      "[388]\tTest-mae:49027.50684\n",
      "[389]\tTest-mae:49004.58166\n",
      "[390]\tTest-mae:48997.86580\n",
      "[391]\tTest-mae:48943.95570\n",
      "[392]\tTest-mae:48911.01853\n",
      "[393]\tTest-mae:48892.61339\n",
      "[394]\tTest-mae:48898.20501\n",
      "[395]\tTest-mae:48871.88595\n",
      "[396]\tTest-mae:48891.35501\n",
      "[397]\tTest-mae:48875.69940\n",
      "[398]\tTest-mae:48902.56276\n",
      "[399]\tTest-mae:48860.40728\n",
      "[400]\tTest-mae:48845.05890\n",
      "[401]\tTest-mae:48831.72102\n",
      "[402]\tTest-mae:48838.70640\n",
      "[403]\tTest-mae:48854.15820\n",
      "[404]\tTest-mae:48827.65816\n",
      "[405]\tTest-mae:48818.09568\n",
      "[406]\tTest-mae:48842.07613\n",
      "[407]\tTest-mae:48821.83856\n",
      "[408]\tTest-mae:48814.51851\n",
      "[409]\tTest-mae:48798.13272\n",
      "[410]\tTest-mae:48756.71861\n",
      "[411]\tTest-mae:48733.19096\n",
      "[412]\tTest-mae:48763.84480\n",
      "[413]\tTest-mae:48736.84644\n",
      "[414]\tTest-mae:48733.73297\n",
      "[415]\tTest-mae:48780.73201\n",
      "[416]\tTest-mae:48805.94647\n",
      "[417]\tTest-mae:48788.47422\n",
      "[418]\tTest-mae:48787.35445\n",
      "[419]\tTest-mae:48776.40562\n",
      "[420]\tTest-mae:48763.78658\n",
      "[421]\tTest-mae:48780.32113\n",
      "Best MAE: 48733.19 in 412 rounds\n"
     ]
    }
   ],
   "source": [
    "#prior\n",
    "# num_boost_round = 100\n",
    "# model = xgb.train(\n",
    "#    params=params,\n",
    "#    dtrain=dtrain_reg,\n",
    "#    num_boost_round=num_boost_round,\n",
    "# ) \n",
    "\n",
    "\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest_reg, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE improvement: Baseline 149360.500 to 48733.19 in 412 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:146222.73493\n",
      "[1]\tTest-mae:145530.41718\n",
      "[2]\tTest-mae:144825.36297\n",
      "[3]\tTest-mae:144115.44565\n",
      "[4]\tTest-mae:143406.69053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tTest-mae:142635.51592\n",
      "[6]\tTest-mae:141928.63962\n",
      "[7]\tTest-mae:141257.88331\n",
      "[8]\tTest-mae:140453.04326\n",
      "[9]\tTest-mae:139735.76603\n",
      "[10]\tTest-mae:139123.43281\n",
      "[11]\tTest-mae:138485.60703\n",
      "[12]\tTest-mae:137836.73694\n",
      "[13]\tTest-mae:137140.64220\n",
      "[14]\tTest-mae:136508.91795\n",
      "[15]\tTest-mae:135810.41610\n",
      "[16]\tTest-mae:135130.49435\n",
      "[17]\tTest-mae:134462.91789\n",
      "[18]\tTest-mae:133763.78533\n",
      "[19]\tTest-mae:133081.16332\n",
      "[20]\tTest-mae:132406.79371\n",
      "[21]\tTest-mae:131787.00684\n",
      "[22]\tTest-mae:131147.76709\n",
      "[23]\tTest-mae:130450.14225\n",
      "[24]\tTest-mae:129800.02321\n",
      "[25]\tTest-mae:129096.22162\n",
      "[26]\tTest-mae:128528.46608\n",
      "[27]\tTest-mae:127926.26507\n",
      "[28]\tTest-mae:127320.50286\n",
      "[29]\tTest-mae:126611.98655\n",
      "[30]\tTest-mae:125994.01779\n",
      "[31]\tTest-mae:125360.20879\n",
      "[32]\tTest-mae:124733.69436\n",
      "[33]\tTest-mae:124095.33561\n",
      "[34]\tTest-mae:123506.39649\n",
      "[35]\tTest-mae:122838.30280\n",
      "[36]\tTest-mae:122207.29581\n",
      "[37]\tTest-mae:121599.71832\n",
      "[38]\tTest-mae:120966.37488\n",
      "[39]\tTest-mae:120374.92470\n",
      "[40]\tTest-mae:119745.96829\n",
      "[41]\tTest-mae:119128.26774\n",
      "[42]\tTest-mae:118505.87935\n",
      "[43]\tTest-mae:117956.14192\n",
      "[44]\tTest-mae:117383.45141\n",
      "[45]\tTest-mae:116745.98549\n",
      "[46]\tTest-mae:116156.38531\n",
      "[47]\tTest-mae:115592.96955\n",
      "[48]\tTest-mae:115053.81096\n",
      "[49]\tTest-mae:114428.63998\n",
      "[50]\tTest-mae:113907.19676\n",
      "[51]\tTest-mae:113269.91508\n",
      "[52]\tTest-mae:112739.83324\n",
      "[53]\tTest-mae:112236.75646\n",
      "[54]\tTest-mae:111705.68455\n",
      "[55]\tTest-mae:111177.27109\n",
      "[56]\tTest-mae:110617.30311\n",
      "[57]\tTest-mae:110090.28784\n",
      "[58]\tTest-mae:109630.50090\n",
      "[59]\tTest-mae:109090.78369\n",
      "[60]\tTest-mae:108587.69584\n",
      "[61]\tTest-mae:108100.07061\n",
      "[62]\tTest-mae:107594.72991\n",
      "[63]\tTest-mae:107087.92457\n",
      "[64]\tTest-mae:106533.61561\n",
      "[65]\tTest-mae:106115.99131\n",
      "[66]\tTest-mae:105646.87129\n",
      "[67]\tTest-mae:105102.75730\n",
      "[68]\tTest-mae:104658.48512\n",
      "[69]\tTest-mae:104237.31909\n",
      "[70]\tTest-mae:103805.14461\n",
      "[71]\tTest-mae:103325.37197\n",
      "[72]\tTest-mae:102907.08103\n",
      "[73]\tTest-mae:102417.69409\n",
      "[74]\tTest-mae:102023.99917\n",
      "[75]\tTest-mae:101563.78623\n",
      "[76]\tTest-mae:101167.38335\n",
      "[77]\tTest-mae:100657.47242\n",
      "[78]\tTest-mae:100194.48474\n",
      "[79]\tTest-mae:99752.31858\n",
      "[80]\tTest-mae:99345.81753\n",
      "[81]\tTest-mae:98857.35962\n",
      "[82]\tTest-mae:98457.30734\n",
      "[83]\tTest-mae:98074.06999\n",
      "[84]\tTest-mae:97646.49796\n",
      "[85]\tTest-mae:97212.04572\n",
      "[86]\tTest-mae:96795.93898\n",
      "[87]\tTest-mae:96419.67711\n",
      "[88]\tTest-mae:96014.89784\n",
      "[89]\tTest-mae:95609.26605\n",
      "[90]\tTest-mae:95209.04999\n",
      "[91]\tTest-mae:94823.35235\n",
      "[92]\tTest-mae:94452.98597\n",
      "[93]\tTest-mae:94081.76403\n",
      "[94]\tTest-mae:93727.96447\n",
      "[95]\tTest-mae:93310.53220\n",
      "[96]\tTest-mae:92929.64578\n",
      "[97]\tTest-mae:92546.10703\n",
      "[98]\tTest-mae:92195.18515\n",
      "[99]\tTest-mae:91840.71216\n",
      "[100]\tTest-mae:91440.48974\n",
      "[101]\tTest-mae:91042.91541\n",
      "[102]\tTest-mae:90643.42906\n",
      "[103]\tTest-mae:90264.66653\n",
      "[104]\tTest-mae:89862.39596\n",
      "[105]\tTest-mae:89469.75318\n",
      "[106]\tTest-mae:89106.10922\n",
      "[107]\tTest-mae:88762.83069\n",
      "[108]\tTest-mae:88442.76799\n",
      "[109]\tTest-mae:88060.20529\n",
      "[110]\tTest-mae:87708.80061\n",
      "[111]\tTest-mae:87361.42630\n",
      "[112]\tTest-mae:87017.36896\n",
      "[113]\tTest-mae:86703.94494\n",
      "[114]\tTest-mae:86424.35643\n",
      "[115]\tTest-mae:86097.59122\n",
      "[116]\tTest-mae:85802.85031\n",
      "[117]\tTest-mae:85523.57070\n",
      "[118]\tTest-mae:85234.04828\n",
      "[119]\tTest-mae:84902.89377\n",
      "[120]\tTest-mae:84615.00412\n",
      "[121]\tTest-mae:84301.74302\n",
      "[122]\tTest-mae:84007.77552\n",
      "[123]\tTest-mae:83687.82951\n",
      "[124]\tTest-mae:83401.59111\n",
      "[125]\tTest-mae:83106.18475\n",
      "[126]\tTest-mae:82845.13274\n",
      "[127]\tTest-mae:82530.81089\n",
      "[128]\tTest-mae:82204.43625\n",
      "[129]\tTest-mae:81868.90418\n",
      "[130]\tTest-mae:81593.75514\n",
      "[131]\tTest-mae:81281.10539\n",
      "[132]\tTest-mae:81026.17969\n",
      "[133]\tTest-mae:80763.00405\n",
      "[134]\tTest-mae:80448.42016\n",
      "[135]\tTest-mae:80152.97523\n",
      "[136]\tTest-mae:79848.68122\n",
      "[137]\tTest-mae:79579.50025\n",
      "[138]\tTest-mae:79309.12200\n",
      "[139]\tTest-mae:79002.36930\n",
      "[140]\tTest-mae:78751.15651\n",
      "[141]\tTest-mae:78456.87106\n",
      "[142]\tTest-mae:78135.13903\n",
      "[143]\tTest-mae:77818.14192\n",
      "[144]\tTest-mae:77569.66928\n",
      "[145]\tTest-mae:77305.82090\n",
      "[146]\tTest-mae:77036.59966\n",
      "[147]\tTest-mae:76761.36401\n",
      "[148]\tTest-mae:76503.74160\n",
      "[149]\tTest-mae:76254.94601\n",
      "[150]\tTest-mae:75976.46733\n",
      "[151]\tTest-mae:75719.84069\n",
      "[152]\tTest-mae:75458.12404\n",
      "[153]\tTest-mae:75208.93466\n",
      "[154]\tTest-mae:74943.36762\n",
      "[155]\tTest-mae:74629.87310\n",
      "[156]\tTest-mae:74358.65017\n",
      "[157]\tTest-mae:74129.44618\n",
      "[158]\tTest-mae:73895.23774\n",
      "[159]\tTest-mae:73652.33050\n",
      "[160]\tTest-mae:73411.34264\n",
      "[161]\tTest-mae:73201.51394\n",
      "[162]\tTest-mae:72948.85775\n",
      "[163]\tTest-mae:72711.50014\n",
      "[164]\tTest-mae:72469.71971\n",
      "[165]\tTest-mae:72240.37481\n",
      "[166]\tTest-mae:71991.65210\n",
      "[167]\tTest-mae:71731.99724\n",
      "[168]\tTest-mae:71486.20164\n",
      "[169]\tTest-mae:71240.37704\n",
      "[170]\tTest-mae:70995.33937\n",
      "[171]\tTest-mae:70803.27449\n",
      "[172]\tTest-mae:70544.09641\n",
      "[173]\tTest-mae:70368.82674\n",
      "[174]\tTest-mae:70128.11649\n",
      "[175]\tTest-mae:69865.20133\n",
      "[176]\tTest-mae:69641.84539\n",
      "[177]\tTest-mae:69415.09424\n",
      "[178]\tTest-mae:69195.11957\n",
      "[179]\tTest-mae:68962.99829\n",
      "[180]\tTest-mae:68730.74066\n",
      "[181]\tTest-mae:68564.08391\n",
      "[182]\tTest-mae:68329.17858\n",
      "[183]\tTest-mae:68129.66328\n",
      "[184]\tTest-mae:67869.29334\n",
      "[185]\tTest-mae:67626.79085\n",
      "[186]\tTest-mae:67413.05742\n",
      "[187]\tTest-mae:67229.28040\n",
      "[188]\tTest-mae:67053.41155\n",
      "[189]\tTest-mae:66835.97808\n",
      "[190]\tTest-mae:66667.04416\n",
      "[191]\tTest-mae:66415.03576\n",
      "[192]\tTest-mae:66171.61895\n",
      "[193]\tTest-mae:65989.26959\n",
      "[194]\tTest-mae:65798.75154\n",
      "[195]\tTest-mae:65598.13409\n",
      "[196]\tTest-mae:65425.15580\n",
      "[197]\tTest-mae:65240.65798\n",
      "[198]\tTest-mae:65050.19133\n",
      "[199]\tTest-mae:64865.05132\n",
      "[200]\tTest-mae:64724.27592\n",
      "[201]\tTest-mae:64574.23484\n",
      "[202]\tTest-mae:64417.76160\n",
      "[203]\tTest-mae:64268.82939\n",
      "[204]\tTest-mae:64093.79244\n",
      "[205]\tTest-mae:63959.42504\n",
      "[206]\tTest-mae:63774.25225\n",
      "[207]\tTest-mae:63601.48593\n",
      "[208]\tTest-mae:63432.14936\n",
      "[209]\tTest-mae:63282.79663\n",
      "[210]\tTest-mae:63132.58767\n",
      "[211]\tTest-mae:62968.88465\n",
      "[212]\tTest-mae:62809.76377\n",
      "[213]\tTest-mae:62607.69886\n",
      "[214]\tTest-mae:62477.80203\n",
      "[215]\tTest-mae:62347.65483\n",
      "[216]\tTest-mae:62189.06594\n",
      "[217]\tTest-mae:62055.96211\n",
      "[218]\tTest-mae:61928.84750\n",
      "[219]\tTest-mae:61793.26348\n",
      "[220]\tTest-mae:61660.21727\n",
      "[221]\tTest-mae:61501.33853\n",
      "[222]\tTest-mae:61379.91477\n",
      "[223]\tTest-mae:61236.25434\n",
      "[224]\tTest-mae:61066.99443\n",
      "[225]\tTest-mae:60883.84579\n",
      "[226]\tTest-mae:60754.12946\n",
      "[227]\tTest-mae:60608.72931\n",
      "[228]\tTest-mae:60453.11294\n",
      "[229]\tTest-mae:60335.93475\n",
      "[230]\tTest-mae:60175.12469\n",
      "[231]\tTest-mae:60069.56196\n",
      "[232]\tTest-mae:59868.61892\n",
      "[233]\tTest-mae:59731.66184\n",
      "[234]\tTest-mae:59600.02328\n",
      "[235]\tTest-mae:59461.86645\n",
      "[236]\tTest-mae:59381.80010\n",
      "[237]\tTest-mae:59256.30044\n",
      "[238]\tTest-mae:59138.45260\n",
      "[239]\tTest-mae:58967.87960\n",
      "[240]\tTest-mae:58855.78573\n",
      "[241]\tTest-mae:58743.08611\n",
      "[242]\tTest-mae:58592.29772\n",
      "[243]\tTest-mae:58491.77569\n",
      "[244]\tTest-mae:58340.80473\n",
      "[245]\tTest-mae:58217.95916\n",
      "[246]\tTest-mae:58064.82845\n",
      "[247]\tTest-mae:57898.80158\n",
      "[248]\tTest-mae:57767.57041\n",
      "[249]\tTest-mae:57640.54515\n",
      "[250]\tTest-mae:57532.95953\n",
      "[251]\tTest-mae:57451.58322\n",
      "[252]\tTest-mae:57311.77501\n",
      "[253]\tTest-mae:57207.31529\n",
      "[254]\tTest-mae:57105.18098\n",
      "[255]\tTest-mae:57008.05972\n",
      "[256]\tTest-mae:56870.09670\n",
      "[257]\tTest-mae:56765.73865\n",
      "[258]\tTest-mae:56631.64569\n",
      "[259]\tTest-mae:56555.07667\n",
      "[260]\tTest-mae:56480.39524\n",
      "[261]\tTest-mae:56379.78043\n",
      "[262]\tTest-mae:56269.56441\n",
      "[263]\tTest-mae:56163.35124\n",
      "[264]\tTest-mae:56053.05183\n",
      "[265]\tTest-mae:55955.54024\n",
      "[266]\tTest-mae:55890.48564\n",
      "[267]\tTest-mae:55782.58070\n",
      "[268]\tTest-mae:55716.13269\n",
      "[269]\tTest-mae:55563.81063\n",
      "[270]\tTest-mae:55394.46625\n",
      "[271]\tTest-mae:55323.69553\n",
      "[272]\tTest-mae:55250.87730\n",
      "[273]\tTest-mae:55106.62040\n",
      "[274]\tTest-mae:54959.16030\n",
      "[275]\tTest-mae:54885.07728\n",
      "[276]\tTest-mae:54790.32070\n",
      "[277]\tTest-mae:54659.24616\n",
      "[278]\tTest-mae:54606.13201\n",
      "[279]\tTest-mae:54523.42841\n",
      "[280]\tTest-mae:54470.62656\n",
      "[281]\tTest-mae:54393.31377\n",
      "[282]\tTest-mae:54297.90875\n",
      "[283]\tTest-mae:54233.79105\n",
      "[284]\tTest-mae:54142.19419\n",
      "[285]\tTest-mae:54063.63534\n",
      "[286]\tTest-mae:53972.22094\n",
      "[287]\tTest-mae:53902.57556\n",
      "[288]\tTest-mae:53817.20703\n",
      "[289]\tTest-mae:53687.58351\n",
      "[290]\tTest-mae:53603.26119\n",
      "[291]\tTest-mae:53527.26261\n",
      "[292]\tTest-mae:53462.95648\n",
      "[293]\tTest-mae:53368.15532\n",
      "[294]\tTest-mae:53295.40063\n",
      "[295]\tTest-mae:53189.17987\n",
      "[296]\tTest-mae:53120.41295\n",
      "[297]\tTest-mae:53016.89594\n",
      "[298]\tTest-mae:52944.32621\n",
      "[299]\tTest-mae:52875.69351\n",
      "[300]\tTest-mae:52752.29541\n",
      "[301]\tTest-mae:52687.85968\n",
      "[302]\tTest-mae:52643.96140\n",
      "[303]\tTest-mae:52559.61764\n",
      "[304]\tTest-mae:52462.80893\n",
      "[305]\tTest-mae:52349.25733\n",
      "[306]\tTest-mae:52294.68631\n",
      "[307]\tTest-mae:52202.14936\n",
      "[308]\tTest-mae:52170.80682\n",
      "[309]\tTest-mae:52091.40728\n",
      "[310]\tTest-mae:52043.60206\n",
      "[311]\tTest-mae:51988.80447\n",
      "[312]\tTest-mae:51915.61408\n",
      "[313]\tTest-mae:51841.70354\n",
      "[314]\tTest-mae:51814.37796\n",
      "[315]\tTest-mae:51757.90241\n",
      "[316]\tTest-mae:51723.21239\n",
      "[317]\tTest-mae:51616.43795\n",
      "[318]\tTest-mae:51537.96061\n",
      "[319]\tTest-mae:51465.23467\n",
      "[320]\tTest-mae:51442.17439\n",
      "[321]\tTest-mae:51378.22031\n",
      "[322]\tTest-mae:51336.18992\n",
      "[323]\tTest-mae:51255.44749\n",
      "[324]\tTest-mae:51206.66235\n",
      "[325]\tTest-mae:51128.71281\n",
      "[326]\tTest-mae:51089.61660\n",
      "[327]\tTest-mae:51016.65915\n",
      "[328]\tTest-mae:50961.59336\n",
      "[329]\tTest-mae:50916.64154\n",
      "[330]\tTest-mae:50872.75914\n",
      "[331]\tTest-mae:50821.98366\n",
      "[332]\tTest-mae:50773.67927\n",
      "[333]\tTest-mae:50729.71450\n",
      "[334]\tTest-mae:50654.54050\n",
      "[335]\tTest-mae:50633.02419\n",
      "[336]\tTest-mae:50622.87333\n",
      "[337]\tTest-mae:50577.72425\n",
      "[338]\tTest-mae:50520.63575\n",
      "[339]\tTest-mae:50553.80509\n",
      "[340]\tTest-mae:50519.57749\n",
      "[341]\tTest-mae:50450.91676\n",
      "[342]\tTest-mae:50414.93542\n",
      "[343]\tTest-mae:50363.22744\n",
      "[344]\tTest-mae:50321.11351\n",
      "[345]\tTest-mae:50256.07630\n",
      "[346]\tTest-mae:50232.25746\n",
      "[347]\tTest-mae:50184.18316\n",
      "[348]\tTest-mae:50121.43135\n",
      "[349]\tTest-mae:50083.48783\n",
      "[350]\tTest-mae:50040.54698\n",
      "[351]\tTest-mae:50017.33717\n",
      "[352]\tTest-mae:49969.28584\n",
      "[353]\tTest-mae:49924.29491\n",
      "[354]\tTest-mae:49893.54586\n",
      "[355]\tTest-mae:49824.01053\n",
      "[356]\tTest-mae:49816.18577\n",
      "[357]\tTest-mae:49763.43943\n",
      "[358]\tTest-mae:49719.96867\n",
      "[359]\tTest-mae:49693.95334\n",
      "[360]\tTest-mae:49637.76959\n",
      "[361]\tTest-mae:49605.01303\n",
      "[362]\tTest-mae:49567.65307\n",
      "[363]\tTest-mae:49544.49358\n",
      "[364]\tTest-mae:49542.93887\n",
      "[365]\tTest-mae:49489.68484\n",
      "[366]\tTest-mae:49465.46332\n",
      "[367]\tTest-mae:49424.35403\n",
      "[368]\tTest-mae:49398.79697\n",
      "[369]\tTest-mae:49449.07081\n",
      "[370]\tTest-mae:49412.85283\n",
      "[371]\tTest-mae:49406.72664\n",
      "[372]\tTest-mae:49396.61859\n",
      "[373]\tTest-mae:49361.24024\n",
      "[374]\tTest-mae:49322.25449\n",
      "[375]\tTest-mae:49300.61927\n",
      "[376]\tTest-mae:49283.72758\n",
      "[377]\tTest-mae:49256.77645\n",
      "[378]\tTest-mae:49231.51214\n",
      "[379]\tTest-mae:49199.37586\n",
      "[380]\tTest-mae:49145.26814\n",
      "[381]\tTest-mae:49169.02841\n",
      "[382]\tTest-mae:49170.13135\n",
      "[383]\tTest-mae:49097.11703\n",
      "[384]\tTest-mae:49066.85564\n",
      "[385]\tTest-mae:49062.15265\n",
      "[386]\tTest-mae:49030.46489\n",
      "[387]\tTest-mae:49021.83178\n",
      "[388]\tTest-mae:49027.50684\n",
      "[389]\tTest-mae:49004.58166\n",
      "[390]\tTest-mae:48997.86580\n",
      "[391]\tTest-mae:48943.95570\n",
      "[392]\tTest-mae:48911.01853\n",
      "[393]\tTest-mae:48892.61339\n",
      "[394]\tTest-mae:48898.20501\n",
      "[395]\tTest-mae:48871.88595\n",
      "[396]\tTest-mae:48891.35501\n",
      "[397]\tTest-mae:48875.69940\n",
      "[398]\tTest-mae:48902.56276\n",
      "[399]\tTest-mae:48860.40728\n",
      "[400]\tTest-mae:48845.05890\n",
      "[401]\tTest-mae:48831.72102\n",
      "[402]\tTest-mae:48838.70640\n",
      "[403]\tTest-mae:48854.15820\n",
      "[404]\tTest-mae:48827.65816\n",
      "[405]\tTest-mae:48818.09568\n",
      "[406]\tTest-mae:48842.07613\n",
      "[407]\tTest-mae:48821.83856\n",
      "[408]\tTest-mae:48814.51851\n",
      "[409]\tTest-mae:48798.13272\n",
      "[410]\tTest-mae:48756.71861\n",
      "[411]\tTest-mae:48733.19096\n"
     ]
    }
   ],
   "source": [
    "# Best rounds known, take out early stopping\n",
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.005,\n",
    "'eval_metric': {'mae','rmse'},\n",
    "'max_depth': 10,\n",
    "'min_child_weight': 5,\n",
    "'objective': 'reg:tree',\n",
    "'subsample': 0.8}\n",
    "\n",
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest_reg, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51757.36527297431"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(best_model.predict(dtest_reg), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT getting same MAE as in last round (48733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
